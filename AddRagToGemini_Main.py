import os
import asyncio
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import Dict

# LlamaIndex RAG Components
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.gemini import Gemini
from llama_index.embeddings.gemini import GeminiEmbedding
from llama_index.core.chat_engine.types import BaseChatEngine
from llama_index.core.chat_engine import CondensePlusContextChatEngine

from google import genai
from google.genai import types
from dotenv import load_dotenv

import uvicorn

load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")


# ãƒ¢ãƒ‡ãƒ«å
def initialize_rag_components() -> CondensePlusContextChatEngine:
    """
    RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã—ã€ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã‚’è¿”ã—ã¾ã™ã€‚
    """
    
    # 1. LlamaIndexã®ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
    Settings.llm = Gemini(
            model="gemini-2.5-flash",
            api_key=API_KEY  # ğŸ‘ˆ settingsã‹ã‚‰ç›´æ¥æ¸¡ã™
        )
    Settings.embed_model = GeminiEmbedding(
            model_name="text-embedding-004",
            api_key=API_KEY  # ğŸ‘ˆ settingsã‹ã‚‰ç›´æ¥æ¸¡ã™
        )

    # 2. çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰
    try:
        # 'docs'ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        documents = SimpleDirectoryReader("./docs").load_data()
    except Exception as e:
        print(f"è­¦å‘Š: 'docs'ãƒ•ã‚©ãƒ«ãƒ€ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚{e}")
        documents = []

    if not documents:
        print("RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãªã„å ´åˆã¯ã€ç©ºã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        index = VectorStoreIndex([])
    else:
        # ãƒ™ã‚¯ãƒˆãƒ«DBã‚’æ§‹ç¯‰ï¼ˆåŸ‹ã‚è¾¼ã¿ç”Ÿæˆã¨ä¿å­˜ï¼‰
        index = VectorStoreIndex.from_documents(documents)
        print(f"RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å®Œäº†ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}")

    # 3. RAGãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã®ä½œæˆ
    chat_engine = CondensePlusContextChatEngine.from_defaults(
        retriever=index.as_retriever(),
        llm=Settings.llm,
        system_prompt="ã‚ãªãŸã¯æä¾›ã•ã‚ŒãŸçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«åŸºã¥ã„ã¦ã®ã¿å›ç­”ã™ã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«æƒ…å ±ãŒãªã„å ´åˆã¯ã€ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ãã®æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ã¨ä¼ãˆã¦ãã ã•ã„ã€‚",
        # å±¥æ­´ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’è¨­å®šã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ãŒã€ä»Šå›ã¯ãƒ¡ãƒ¢ãƒªå†…ã§ç®¡ç†ã—ã¾ã™ã€‚
    )
    return chat_engine




# ğŸš¨ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«RAGã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ– ğŸš¨
try:
    RAG_CHAT_ENGINE = initialize_rag_components()
except Exception as e:
    raise RuntimeError(f"RAGã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


# --- 3. FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®šç¾© ---
app = FastAPI()
chat_engines: Dict[str, BaseChatEngine] = {}

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    user_id: str
    message: str


# --- 4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ (éåŒæœŸã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆ) ---
async def generate_rag_stream(engine: BaseChatEngine, prompt: str):
    """LlamaIndexã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å‡¦ç†ã™ã‚‹éåŒæœŸã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿"""
    try:
        # éåŒæœŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã€å¿œç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
        response_stream = await engine.astream_chat(prompt) 

        # å¿œç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã®é€šå¸¸ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ (.response_gen) ã‚’é€šå¸¸ã® for ã§å‡¦ç†
        # éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶­æŒã™ã‚‹ãŸã‚ã€ãƒ«ãƒ¼ãƒ—å†…ã§ await asyncio.sleep(0) ã‚’å®Ÿè¡Œ
        for token in response_stream.response_gen:
            if token:
                yield token 
                await asyncio.sleep(0)

    except Exception as e:
        print(f"RAG/APIã‚¨ãƒ©ãƒ¼: {e}")
        yield f"\n[ERROR] RAG/APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"


# --- 5. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    user_id = request.user_id
    prompt = request.message
    
    if user_id not in chat_engines:
        # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã€å±¥æ­´ã‚’ç‹¬ç«‹ã•ã›ã‚‹
        chat_engines[user_id] = RAG_CHAT_ENGINE
        print(f"æ–°è¦RAGã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {user_id}")
    
    chat_engine = chat_engines[user_id]
    
    return StreamingResponse(
        generate_rag_stream(chat_engine, prompt),
        media_type="text/plain" 
    )